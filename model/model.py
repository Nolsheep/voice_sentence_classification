import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, f1_score, confusion_matrix
import joblib  # à¸ªà¸³à¸«à¸£à¸±à¸š save model

# ğŸ“ à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
os.makedirs("results", exist_ok=True)

# ğŸ”„ à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
df = pd.read_csv("voice_features.csv")
X = df.drop(['label', 'filename'], axis=1, errors='ignore').values
y = df['label']
if y.dtype == 'O':
    y = y.map({'PD': 1, 'Control': 0}).values

# ğŸ¯ Cross-validation
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
accs, aucs, recalls, f1s = [], [], [], []
all_cm = np.zeros((2, 2))
best_f1 = 0
best_model = None

metrics_list = []

for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    sm = SMOTE(random_state=42)
    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

    clf = RandomForestClassifier(
        n_estimators=300,
        random_state=42,
        class_weight='balanced',
        min_samples_leaf=2,
        max_features='sqrt'
    )
    clf.fit(X_train_res, y_train_res)
    y_pred = clf.predict(X_test)
    y_prob = clf.predict_proba(X_test)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_prob)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    cm = confusion_matrix(y_test, y_pred)

    accs.append(acc)
    aucs.append(auc)
    recalls.append(recall)
    f1s.append(f1)
    all_cm += cm

    metrics_list.append([fold + 1, acc, auc, recall, f1])
    print(f"Fold {fold+1}: acc={acc:.3f}, auc={auc:.3f}, recall={recall:.3f}, f1={f1:.3f}")
    print("Confusion Matrix:\n", cm)
    print("-" * 50)

    # ğŸ“Œ Save best fold model
    if f1 > best_f1:
        best_f1 = f1
        best_model = clf

# ğŸ’¾ Save best fold model
joblib.dump(best_model, "results/best_model.pkl")
print("ğŸ’¾ Saved best fold model to results/best_model.pkl")

# ğŸ“ Save metrics to CSV
metrics_df = pd.DataFrame(metrics_list, columns=["Fold", "Accuracy", "AUC", "Recall_PD", "F1_PD"])
metrics_df.to_csv("results/metrics_per_fold.csv", index=False)

# ğŸ“ Save average metrics
with open("results/summary.txt", "w", encoding="utf-8") as f:
    f.write("==== à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ 10-Fold ====\n")
    f.write(f"Accuracy: {np.mean(accs):.3f} Â± {np.std(accs):.3f}\n")
    f.write(f"AUC: {np.mean(aucs):.3f} Â± {np.std(aucs):.3f}\n")
    f.write(f"Recall (PD): {np.mean(recalls):.3f}\n")
    f.write(f"F1 (PD): {np.mean(f1s):.3f}\n")
    f.write("Confusion Matrix sum:\n")
    f.write(str(all_cm.astype(int)))

# ğŸ“Š Plot Confusion Matrix (à¹à¸šà¸š integer à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™)
plt.figure(figsize=(6, 5))
sns.heatmap(all_cm.astype(int), annot=True, fmt="d", cmap="Blues",
            xticklabels=["Control", "PD"], yticklabels=["Control", "PD"])
plt.title("Confusion Matrix (10-Fold Sum)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.savefig("results/confusion_matrix.png")
plt.close()


# ğŸ“ˆ Plot Metrics over Folds
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), accs, marker='o', label='Accuracy')
plt.plot(range(1, 11), aucs, marker='o', label='AUC')
plt.plot(range(1, 11), recalls, marker='o', label='Recall (PD)')
plt.plot(range(1, 11), f1s, marker='o', label='F1 (PD)')
plt.xticks(range(1, 11))
plt.xlabel("Fold")
plt.ylabel("Score")
plt.title("Metrics per Fold")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("results/metrics_per_fold.png")
plt.close()

# âœ… à¹€à¸—à¸£à¸™à¹ƒà¸«à¸¡à¹ˆà¸šà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸£à¸´à¸‡
final_model = RandomForestClassifier(
    n_estimators=300,
    random_state=42,
    class_weight='balanced',
    min_samples_leaf=2,
    max_features='sqrt'
)

# âš™ï¸ à¸—à¸³ SMOTE à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
sm = SMOTE(random_state=42)
X_full_res, y_full_res = sm.fit_resample(X, y)
final_model.fit(X_full_res, y_full_res)

# ğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ final_model à¸à¸£à¹‰à¸­à¸¡ feature_names
feature_names = df.drop(['label', 'filename'], axis=1, errors='ignore').columns.tolist()
model_package = {
    "model": final_model,
    "feature_names": feature_names
}
joblib.dump(model_package, "results/final_model_for_use.pkl")
print("âœ… Saved final model (trained on all data) to results/final_model_for_use.pkl")

print("ğŸ“Š All metrics, models, and plots saved in folder: results/")
